{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron dataframe:\n",
      "   id   model_id      x_soma      y_soma      z_soma  rotation_angle_yaxis  \\\n",
      "0   0  100000101  110.906706 -431.668136  623.732700              1.247325   \n",
      "1   1  100000101  526.329919 -564.693981 -555.341582              3.418240   \n",
      "2   2  100000101  197.897567 -505.737886  709.692990              0.463397   \n",
      "3   3  100000101  400.302561 -465.458859 -224.639993              4.102361   \n",
      "4   4  100000101 -766.751467 -556.178476   55.929619              2.800441   \n",
      "\n",
      "    pop_name ei location  tuning_angle  \n",
      "0  LIFe5Rbp4  e    VisL5      0.000000  \n",
      "1  LIFe5Rbp4  e    VisL5      0.017278  \n",
      "2  LIFe5Rbp4  e    VisL5      0.034556  \n",
      "3  LIFe5Rbp4  e    VisL5      0.051833  \n",
      "4  LIFe5Rbp4  e    VisL5      0.069111  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os.path\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "import sys\n",
    "import F1F0\n",
    "\n",
    "from var_utils import *\n",
    "\n",
    "save_result_dir = r\"./\"\n",
    "dir_syn = r\"./biophysical\"\n",
    "# dir_stp = r\"//allen/programs/braintv/workgroups/v1column/binghuangc/network_effect/Column_Simulation/STP_update_syn_tau/run_spike_trains/results/\"\n",
    "\n",
    "\n",
    "# Load the nodes\n",
    "nodes_DF = pd.read_csv('../Biophysical_network/net/v1_nodes.csv', sep = ' ')\n",
    "print \"Neuron dataframe:\"\n",
    "print nodes_DF.head()\n",
    "\n",
    "orientations = np.arange(0,360,45)\n",
    "trials = np.arange(10)\n",
    "stimulusTypeName = \"gratings\"\n",
    "total_n_neurons = 230924\n",
    "np.random.seed(100)\n",
    "\n",
    "pop_names_bph = np.array(['e23Cux2', 'e4Rorb', 'e4Nr5a1' , 'e4Scnn1a', 'e4other','e5Rbp4','e5noRbp4', 'e6Ntsr1'\n",
    "                , 'i23Pvalb', 'i1Htr3a','i23Htr3a','i23Sst', 'i4Pvalb', 'i4Htr3a', 'i4Sst', 'i5Pvalb'\n",
    "                 , 'i5Sst', 'i5Htr3a', 'i6Pvalb', 'i6Sst', 'i6Htr3a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_resp_spk(spike_data, n_neurons, start_time, end_time, win_size, bin_stride):\n",
    "    # assumes spike_data DataFrame\n",
    "    spike_rate = np.zeros((n_neurons,len(range(start_time, end_time, bin_stride))))           \n",
    "    for l_ind, t_ind in enumerate(range(start_time,end_time, bin_stride)):\n",
    "        count_loop = spike_data[spike_data[\"time\"]>t_ind][spike_data[\"time\"]<t_ind+win_size].groupby(\"cell\")[\"time\"].count()\n",
    "        spike_rate[count_loop.index,l_ind] = count_loop\n",
    "    #print \"Done!\"\n",
    "    return spike_rate\n",
    "\n",
    "def sig_cor_across_pop(total_spike_count1, total_spike_count2, remove_nans):\n",
    "    # assumes total_spike_count has size m*n*r where m is number of neurons, n is number of orientations\n",
    "    # and r is number of trials\n",
    "    # assumes remove_nans is a binary flag\n",
    "    \n",
    "    spike_corrs_exc = []\n",
    "    \n",
    "    trial_ave_spike_exc1 = np.nanmean(total_spike_count1, axis = 2)\n",
    "    trial_ave_spike_exc2 = np.nanmean(total_spike_count2, axis = 2)\n",
    "    \n",
    "    for i in range(trial_ave_spike_exc1.shape[0]):\n",
    "        for j in range(trial_ave_spike_exc2.shape[0]):\n",
    "            spike_corrs_exc.append(np.corrcoef((trial_ave_spike_exc1[i,:],trial_ave_spike_exc2[j,:]))[0,1])\n",
    "        \n",
    "    tempR_exc = np.array(spike_corrs_exc)\n",
    "    print tempR_exc.shape\n",
    "#     tempR_exc = np.tril(spike_corrs_exc)\n",
    "#     tempR_exc = tempR_exc[np.tril_indices(int(np.sqrt(tempR_exc.size)), -1)]\n",
    "    if remove_nans:\n",
    "        tempR_exc = tempR_exc[~np.isnan(tempR_exc)]        \n",
    "    return tempR_exc\n",
    "\n",
    "def change_bin_win(spike_rate_ephys_1ms, win_size):\n",
    "    spike_rate_ephys = np.zeros((spike_rate_ephys_1ms.shape[0], np.int(spike_rate_ephys_1ms.shape[1]/win_size)+1, spike_rate_ephys_1ms.shape[2]))\n",
    "    for bin_ind, bin_edge in enumerate(range(0,spike_rate_ephys_1ms.shape[1],win_size)):\n",
    "        spike_rate_ephys[:,bin_ind,:] = np.sum(spike_rate_ephys_1ms[:,bin_edge:bin_edge+win_size,:], axis=1)\n",
    "    return spike_rate_ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for trial:  0\n",
      "Data loaded for trial:  1\n",
      "Data loaded for trial:  2\n",
      "Data loaded for trial:  3\n",
      "Data loaded for trial:  4\n",
      "Data loaded for trial:  5\n",
      "Data loaded for trial:  6\n",
      "Data loaded for trial:  7\n",
      "Data loaded for trial:  8\n",
      "Data loaded for trial:  9\n",
      "Data loaded for trial:  0\n",
      "Data loaded for trial:  1\n",
      "Data loaded for trial:  2\n",
      "Data loaded for trial:  3\n",
      "Data loaded for trial:  4\n",
      "Data loaded for trial:  5\n",
      "Data loaded for trial:  6\n",
      "Data loaded for trial:  7\n",
      "Data loaded for trial:  8\n",
      "Data loaded for trial:  9\n"
     ]
    }
   ],
   "source": [
    "# parameters for calculation of firing rate over step\n",
    "\n",
    "flash_types = ['on', 'off']\n",
    "\n",
    "win_size = 10\n",
    "bin_stride = 10\n",
    "\n",
    "for flash_type in flash_types:\n",
    "    \n",
    "    if flash_type == 'on':\n",
    "        end_time = 750\n",
    "        start_time = 500\n",
    "        \n",
    "    elif flash_type == 'off':\n",
    "        end_time = 2000\n",
    "        start_time = 1750\n",
    "\n",
    "    spike_rates = np.zeros((total_n_neurons, (end_time - start_time)/bin_stride, trials.shape[0]))\n",
    "\n",
    "    for t in trials:\n",
    "        if stimulusTypeName == \"gratings\":\n",
    "            run_name = 'output_trial'+str(t)+'/spikes.txt'\n",
    "    #                 spikes = np.loadtxt(dir_syn+spikes_file_name, unpack=True)\n",
    "    #                 run_name =  'full3_GScorrected_PScorrected_3.0sec_SF0.04_TF2.0_ori'+str(o)+'.0_c80.0_gs0.5_spikes/trial_'+str(t)+'/output/spikes.txt'\n",
    "            spike_file = os.path.join(dir_syn, run_name)\n",
    "            spike_data = pd.read_table(spike_file, sep=\" \", names=[\"time\", \"cell\"])\n",
    "    #                 spike_data = spike_data.ix[spike_data[\"cell\"] < total_n_neurons, :] # don't care about LIFs\n",
    "            spike_data = spike_data.ix[spike_data[\"time\"] > 0, :] # remove the spont part\n",
    "            spike_rates[:,:,t] = spike_rates[:,:,t] + bin_resp_spk(spike_data, total_n_neurons, start_time, end_time, win_size, bin_stride) \n",
    "        print \"Data loaded for trial: \", t\n",
    "\n",
    "    np.save(save_result_dir+'spike_rates_250msFlashes_'+flash_type+'.npy', spike_rates)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to make directories for saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43394,)\n",
      "(8584,)\n",
      "total number of neurons:  1000\n",
      "(1000, 1000)\n",
      "Signal correlation Done!\n",
      "total number of neurons:  1000\n",
      "(1000, 1000)\n",
      "Signal correlation Done!\n",
      "total number of neurons:  2000\n",
      "(2000, 2000)\n",
      "Signal correlation Done!\n",
      "total number of neurons:  1000\n",
      "(1000, 1000)\n",
      "Signal correlation Done!\n",
      "total number of neurons:  1000\n",
      "(1000, 1000)\n",
      "Signal correlation Done!\n",
      "total number of neurons:  2000\n",
      "(2000, 2000)\n",
      "Signal correlation Done!\n",
      "(1000000,)\n",
      "Signal correlation Done!\n",
      "(1000000,)\n",
      "Signal correlation Done!\n"
     ]
    }
   ],
   "source": [
    "flash_types = ['on', 'off']\n",
    "connection_types = ['ee', 'ii', 'all']\n",
    "\n",
    "np.random.seed(0)\n",
    "tot_rand = 1000\n",
    "\n",
    "inds_e_all = np.where(nodes_DF.pop_name.str.startswith('e'))[0]\n",
    "print inds_e_all.shape\n",
    "inds_e = np.random.choice(inds_e_all, tot_rand, replace=False)\n",
    "\n",
    "inds_i_all = np.where(nodes_DF.pop_name.str.startswith('i'))[0]\n",
    "print inds_i_all.shape\n",
    "inds_i = np.random.choice(inds_i_all, tot_rand, replace=False)\n",
    "\n",
    "for flash_type in flash_types:\n",
    "    \n",
    "    total_spike_count = np.load(save_result_dir+'spike_rates_250msFlashes_'+flash_type+'.npy')\n",
    "\n",
    "    for connection_type in connection_types:\n",
    "        \n",
    "        if connection_type == 'ee':\n",
    "            total_spike_count_pop = total_spike_count[inds_e,:,:]\n",
    "            print 'total number of neurons: ', total_spike_count_pop.shape[0]\n",
    "            \n",
    "        elif connection_type == 'ii':\n",
    "            total_spike_count_pop = total_spike_count[inds_i,:,:]\n",
    "            print 'total number of neurons: ', total_spike_count_pop.shape[0]\n",
    "            \n",
    "        elif connection_type == 'all':\n",
    "            total_spike_count_pop = total_spike_count[np.union1d(inds_e,inds_i),:,:]\n",
    "            print 'total number of neurons: ', total_spike_count_pop.shape[0]\n",
    "\n",
    "        sig_cors = sig_cor(total_spike_count_pop, 0)\n",
    "        print 'Signal correlation Done!'\n",
    "    #     noise_cors = noise_cor(total_spike_count_pop, 0)\n",
    "    #     print 'Noise correlation Done!'\n",
    "\n",
    "    #     sig_noise_cors = sig_noise_cor(sig_cors,noise_cors)\n",
    "    # #         plot_sig_noise_cor(tempR_sig,tempR_noise)\n",
    "\n",
    "        np.savez(save_result_dir+'corrs/250msflashes/biophysical/corrs_250msFlashes_'+flash_type+'_'+connection_type+'.npz', sig_cors = sig_cors)\n",
    "        \n",
    "#ei\n",
    "for flash_type in flash_types:\n",
    "    \n",
    "    total_spike_count = np.load(save_result_dir+'spike_rates_250msFlashes_'+flash_type+'.npy')\n",
    "    sig_cors = sig_cor_across_pop(total_spike_count[inds_e,:,:], total_spike_count[inds_i,:,:], 0)\n",
    "    print 'Signal correlation Done!'\n",
    "    \n",
    "    np.savez(save_result_dir+'corrs/250msflashes/biophysical/corrs_250msFlashes_'+flash_type+'_ei.npz', sig_cors = sig_cors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
