{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_session import (\n",
    "    EcephysSession, \n",
    "    removed_unused_stimulus_presentation_columns\n",
    ")\n",
    "from allensdk.brain_observatory.ecephys.visualization import plot_mean_waveforms, plot_spike_counts, raster_plot\n",
    "\n",
    "# tell pandas to show all columns when we display a DataFrame\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_borders = [0, 100, 310, 430, 650, 850] # [1E-6*m]\n",
    "layerpop_names = ['e23', 'e4', 'e5', 'e6', 'i1', 'i23', 'i4', 'i5', 'i6']\n",
    "nlayers = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sessions_data_dir = '/Volumes/My Passport/ecephys_cache_dir_10_31'\n",
    "\n",
    "manifest_path = os.path.join(exp_sessions_data_dir, \"manifest.json\")\n",
    "\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_session_ids = [int(f.path.split('/')[-1].split('_')[-1]) for f in os.scandir(exp_sessions_data_dir ) if f.is_dir()]\n",
    "list_session_ids_string = [f.path.split('/')[-1].split('_')[-1] for f in os.scandir(exp_sessions_data_dir ) if f.is_dir()]\n",
    "nsessions = len(list_session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[715093703]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_session_ids = [list_session_ids[0]]\n",
    "list_session_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sessions = [cache.get_session_data(session_id) for session_id in list_session_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = cache.get_channels()\n",
    "units = cache.get_units()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find depth of units in each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_VISp_session_depth = []\n",
    "for i, session_id in enumerate(list_session_ids):\n",
    "    # Get channels in VISp for each session\n",
    "    channels_session = channels.loc[channels['ecephys_session_id'] == session_id]\n",
    "    channels_VISp_session = channels_session.loc[channels_session['ecephys_structure_acronym'] == 'VISp']\n",
    "    \n",
    "    # Get units in VISp for each session\n",
    "    units_session = units.loc[units['ecephys_session_id'] == session_id]\n",
    "    units_VISp_session = units_session.loc[units_session['ecephys_structure_acronym'] == 'VISp']\n",
    "    \n",
    "    # Distance from tip of probe is depth of each unit\n",
    "    units_VISp_session_depth_temp = abs(units_VISp_session['probe_vertical_position']-channels_VISp_session['probe_vertical_position'].max())\n",
    "    units_VISp_session_depth.append(units_VISp_session_depth_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying which units are excitatory and inhibitory based on peak-to-peak width\n",
    "- Smaller p2p width than 0.4 ms --> fast-spiking, i.e. inhibitory cells\n",
    "- Greater p2p width than 0.4 ms --> regular-spiking, i.e. excitatory cells\n",
    "- Otherwise: Cannot determine whether cell is inhibitory of excitatory based on waveform, so it is disregarded\n",
    "- Note: This calculation takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2p_width:  0.5000002421731657\n",
      "p2p_width:  -0.6666669895642209\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  1.0333338338245424\n",
      "p2p_width:  0.3666668442603216\n",
      "p2p_width:  0.7333336885206431\n",
      "p2p_width:  1.9000009202580297\n",
      "p2p_width:  0.7666670379988542\n",
      "p2p_width:  -0.16666674739105528\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  -0.766667037998854\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  0.43333354321674356\n",
      "p2p_width:  0.3666668442603216\n",
      "p2p_width:  0.700000339042432\n",
      "p2p_width:  0.733333688520643\n",
      "p2p_width:  2.0000009686926625\n",
      "p2p_width:  -0.5000002421731656\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  0.6000002906077988\n",
      "p2p_width:  0.6333336400860099\n",
      "p2p_width:  1.6333341244323414\n",
      "p2p_width:  0.26666679582568836\n",
      "p2p_width:  1.6666674739105525\n",
      "p2p_width:  0.30000014530389946\n",
      "p2p_width:  1.7333341728669742\n",
      "p2p_width:  0.6000002906077988\n",
      "p2p_width:  -0.13333339791284407\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  0.7666670379988542\n",
      "p2p_width:  0.8333337369552761\n",
      "p2p_width:  1.2666672801720196\n",
      "p2p_width:  0.26666679582568836\n",
      "p2p_width:  -0.5333335916513766\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  0.23333344634747727\n",
      "p2p_width:  0.5666669411295877\n",
      "p2p_width:  0.5000002421731656\n",
      "p2p_width:  0.3666668442603216\n",
      "p2p_width:  0.5000002421731656\n",
      "p2p_width:  0.6666669895642209\n",
      "p2p_width:  0.800000387477065\n",
      "p2p_width:  0.8666670864334872\n",
      "p2p_width:  0.43333354321674356\n",
      "p2p_width:  0.6000002906077987\n",
      "p2p_width:  0.700000339042432\n",
      "p2p_width:  0.5333335916513766\n",
      "p2p_width:  0.5666669411295877\n",
      "p2p_width:  0.6333336400860099\n",
      "p2p_width:  0.43333354321674367\n",
      "p2p_width:  0.700000339042432\n",
      "p2p_width:  0.5333335916513766\n",
      "p2p_width:  0.5333335916513766\n",
      "p2p_width:  0.5333335916513766\n",
      "p2p_width:  0.700000339042432\n",
      "p2p_width:  2.0000009686926625\n",
      "p2p_width:  1.4000006780848642\n",
      "p2p_width:  -0.46666689269495454\n",
      "Can't determine whether inhibitory or excitatory. Disregard.\n",
      "p2p_width:  1.6666674739105525\n",
      "p2p_width:  1.500000726519497\n",
      "p2p_width:  0.7666670379988542\n",
      "p2p_width:  0.3666668442603216\n",
      "p2p_width:  0.33333349478211044\n",
      "p2p_width:  0.6333336400860099\n",
      "p2p_width:  0.700000339042432\n",
      "p2p_width:  2.0000009686926625\n"
     ]
    }
   ],
   "source": [
    "exc_nrns_list = []; inh_nrns_list = []\n",
    "\n",
    "for i, session in enumerate(list_sessions):\n",
    "    units_of_interest = units_VISp_session_depth[i].index.to_numpy()\n",
    "    \n",
    "    waveforms = {uid: session.mean_waveforms[uid] for uid in units_of_interest}\n",
    "    peak_channels = {uid: session.units.loc[uid, 'peak_channel_id'] for uid in units_of_interest}\n",
    "    \n",
    "    p2p_width = np.zeros(len(units_of_interest))\n",
    "    \n",
    "    \n",
    "    nrn_type_mark = {} # Did not end up using this\n",
    "    \n",
    "    exc_nrns_list_temp = []; inh_nrns_list_temp = []\n",
    "    p2p_cut_off = 0.4 # (ms)\n",
    "    for i, unit_nr in enumerate(units_of_interest):\n",
    "        mean_waveform = np.mean(waveforms[unit_nr], axis = 0)\n",
    "        time_max_peak = waveforms[unit_nr].time[np.argmax(mean_waveform)]\n",
    "        #print('time_max_peak: ', time_max_peak)\n",
    "        time_min_peak = waveforms[unit_nr].time[np.argmin(mean_waveform)]\n",
    "        #print('time_min_peak: ', time_min_peak)\n",
    "        p2p_width[i] = (time_max_peak-time_min_peak)*1E3\n",
    "        print('p2p_width: ', p2p_width[i])\n",
    "\n",
    "        if p2p_width[i] > p2p_cut_off:\n",
    "            nrn_type_mark[unit_nr] = 'e' # excitatory\n",
    "            exc_nrns_list_temp.append(unit_nr)\n",
    "        elif p2p_width[i] < p2p_cut_off and p2p_width[i] > 0:\n",
    "            nrn_type_mark[unit_nr] = 'i' # inhibitory\n",
    "            inh_nrns_list_temp.append(unit_nr)\n",
    "        else:\n",
    "            print(\"Can't determine whether inhibitory or excitatory. Disregard.\")\n",
    "\n",
    "    exc_nrns_list.append(np.asarray(exc_nrns_list_temp))\n",
    "    inh_nrns_list.append(np.asarray(inh_nrns_list_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the units by layer and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 100, 310, 430, 650, 850]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inh_units_layers[i-1]:  []\n",
      "exc_units_layers[i-1]:  []\n",
      "100 0\n",
      "100 0\n",
      "inh_units_layers[i-1]:  []\n",
      "exc_units_layers[i-1]:  [950932445, 950932563, 950932578, 950932696, 950933960]\n",
      "310 5\n",
      "310 5\n",
      "inh_units_layers[i-1]:  []\n",
      "exc_units_layers[i-1]:  [950933924]\n",
      "430 1\n",
      "430 1\n",
      "inh_units_layers[i-1]:  [950931254, 950931315, 950931423, 950933840]\n",
      "exc_units_layers[i-1]:  [950931164, 950931181, 950931236, 950931272, 950931458, 950931363, 950931517, 950931533, 950931565, 950931581, 950931617, 950931805, 950931656, 950931727, 950931751, 950931770, 950931853, 950931878, 950931899, 950931959, 950932032, 950933907, 950932087, 950932102, 950933890]\n",
      "650 29\n",
      "650 29\n",
      "inh_units_layers[i-1]:  [950930237, 950930407, 950930964, 950930985, 950933732]\n",
      "exc_units_layers[i-1]:  [950930105, 950930145, 950930215, 950933698, 950930276, 950930340, 950930358, 950930375, 950930392, 950930423, 950930437, 950930454, 950930522, 950930795, 950930866, 950930888, 950934181, 950931004, 950931118, 950931043]\n",
      "850 25\n",
      "850 25\n"
     ]
    }
   ],
   "source": [
    "inh_units_layers_all_sessions = [[]]*nsessions; exc_units_layers_all_sessions = [[]]*nsessions;\n",
    "\n",
    "ninh_nrns = 0; nexc_nrns = 0 # just counters used for checks\n",
    "for k, session in enumerate(list_sessions):\n",
    "    \n",
    "    inh_units_layers_temp = [[]]*nlayers\n",
    "    exc_units_layers_temp = [[]]*nlayers\n",
    "    for i in range(1, len(layer_borders)):\n",
    "        # mask to get units in between borders of a layer\n",
    "        mask = np.logical_and(units_VISp_session_depth[k] <= layer_borders[i], units_VISp_session_depth[k] > layer_borders[i-1])\n",
    "\n",
    "        temp_units_VISp_session_layers = units_VISp_session_depth[k][mask]\n",
    "        #units_VISp_session_layers.append(temp_units_VISp_session_layers)\n",
    "        \n",
    "        # All units in layer gathered (not really used for anything)\n",
    "        nrns_in_layer = temp_units_VISp_session_layers.keys().to_numpy()\n",
    "        #print('nrns_in_layer: ', nrns_in_layer)\n",
    "        \n",
    "        # Separate inhibitory and excitatory units based on identification above\n",
    "        temp_inh_units_layers = []\n",
    "        temp_exc_units_layers = []\n",
    "        j = 0\n",
    "        while j < len(nrns_in_layer):\n",
    "            if nrns_in_layer[j] in inh_nrns_list[k]:\n",
    "                temp_inh_units_layers.append(nrns_in_layer[j])\n",
    "                ninh_nrns += 1\n",
    "            else:\n",
    "                if layer_borders[i] != 100: # not supposed to be any excitatory neurons in layer 1\n",
    "                    temp_exc_units_layers.append(nrns_in_layer[j])\n",
    "                    nexc_nrns += 1\n",
    "            j += 1\n",
    "        inh_units_layers_temp[i-1] = temp_inh_units_layers\n",
    "        exc_units_layers_temp[i-1] = temp_exc_units_layers\n",
    "        print('inh_units_layers[i-1]: ', inh_units_layers_temp[i-1])\n",
    "        print('exc_units_layers[i-1]: ', exc_units_layers_temp[i-1])\n",
    "        print(layer_borders[i], (len(inh_units_layers_temp[i-1])+len(exc_units_layers_temp[i-1])))\n",
    "        print(layer_borders[i], len(nrns_in_layer))\n",
    "    \n",
    "    inh_units_layers_all_sessions[k] = inh_units_layers_temp\n",
    "    exc_units_layers_all_sessions[k] = exc_units_layers_temp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009983361064891847\n"
     ]
    }
   ],
   "source": [
    "time_bin_start = -0.1 # seconds before stimulus onset\n",
    "time_bin_end = 0.5 # seconds after stimulus onset\n",
    "nbins_pr_second = 1000 # 1 ms bins\n",
    "nbins = int((time_bin_end-time_bin_start)*nbins_pr_second+1)\n",
    "time_bin_edges = np.linspace(time_bin_start, time_bin_end, nbins)\n",
    "\n",
    "ratio_bins_second = (time_bin_end-time_bin_start)/nbins\n",
    "print(ratio_bins_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_twoi = 0 # start time window of interest (ms)\n",
    "end_twoi = 100 # end time window of interest (ms)\n",
    "\n",
    "# Index time window of interest for simulations\n",
    "idx_start_twoi_sim = start_twoi+500 \n",
    "idx_end_twoi_sim = end_twoi+500\n",
    "\n",
    "# Index time window of interest for experimental data\n",
    "idx_start_twoi_exp = int(start_twoi/(ratio_bins_second*1E3) - time_bin_edges[0]/ratio_bins_second)\n",
    "idx_end_twoi_exp = int(end_twoi/(ratio_bins_second*1E3) - time_bin_edges[0]/ratio_bins_second)\n",
    "len_idx_twoi_exp = idx_end_twoi_exp - idx_start_twoi_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'white'\n",
    "if color == 'white':\n",
    "    stim_type = 0\n",
    "    color_mask = 1\n",
    "if color == 'black':\n",
    "    stim_type = 1\n",
    "    color_mask = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e23', 'e4', 'e5', 'e6', 'i1', 'i23', 'i4', 'i5', 'i6']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerpop_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract spike times and compute firing rates\n",
    "- Note: This takes a long time. If you want to test things I'd recommend you to start with only first 10 sessions or so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Session:  0 , Session label:  715093703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atleeskelandrimehaug/opt/anaconda3/envs/gen_env/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  del sys.path[0]\n",
      "/Users/atleeskelandrimehaug/opt/anaconda3/envs/gen_env/lib/python3.7/site-packages/allensdk/brain_observatory/ecephys/ecephys_session.py:1093: UserWarning: Session includes invalid time intervals that could be accessed with the attribute 'invalid_times',Spikes within these intervals are invalid and may need to be excluded from the analysis.\n",
      "  warnings.warn(\"Session includes invalid time intervals that could be accessed with the attribute 'invalid_times',\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stimulus was presented  True\n",
      "Pop:  e23\n",
      "n_exc_units_in_pop:  5\n",
      "shape temp_spike_counts.T:  (5, 600, 75)\n",
      "Pop:  e4\n",
      "n_exc_units_in_pop:  1\n",
      "shape temp_spike_counts.T:  (1, 600, 75)\n",
      "Pop:  e5\n",
      "n_exc_units_in_pop:  25\n",
      "shape temp_spike_counts.T:  (25, 600, 75)\n",
      "Pop:  e6\n",
      "n_exc_units_in_pop:  20\n",
      "shape temp_spike_counts.T:  (20, 600, 75)\n",
      "Pop:  i1\n",
      "n_inh_units_in_layer:  0\n",
      "Pop:  i23\n",
      "n_inh_units_in_layer:  0\n",
      "Pop:  i4\n",
      "n_inh_units_in_layer:  0\n",
      "Pop:  i5\n",
      "n_inh_units_in_layer:  4\n",
      "shape temp_spike_counts.T:  (4, 600, 75)\n",
      "Pop:  i6\n",
      "n_inh_units_in_layer:  5\n",
      "shape temp_spike_counts.T:  (5, 600, 75)\n"
     ]
    }
   ],
   "source": [
    "# Firing rates of units in different layer populations separated by individual sessions \n",
    "fir_rates_all_cells_sessions = {}\n",
    "\n",
    "for sesNr, session in enumerate(list_sessions):\n",
    "    print('------------------------------------------------\\n\\n')\n",
    "    print('Session: ', sesNr, ', Session label: ', list_session_ids[sesNr])\n",
    "    \n",
    "    # look at responses to the flash stimulus\n",
    "    flash_250_ms_stimulus_presentation = session.stimulus_presentations[\n",
    "        session.stimulus_presentations['stimulus_name'] == 'flashes'\n",
    "    ]\n",
    "    flash_250_ms_stimulus_presentation_ids = flash_250_ms_stimulus_presentation[\n",
    "        session.stimulus_presentations.color == color_mask].index.values\n",
    "    \n",
    "    print('The stimulus was presented ', np.any(flash_250_ms_stimulus_presentation_ids))\n",
    "    \n",
    "    if np.any(flash_250_ms_stimulus_presentation_ids):\n",
    "        fir_rate_all_cells_layers = {}\n",
    "        for layPopNr, layPopName in enumerate(layerpop_names):\n",
    "            print('Pop: ', layPopName)\n",
    "            if layPopName[0] == 'i':\n",
    "                units_of_interest = inh_units_layers_all_sessions[sesNr][layPopNr-4]\n",
    "                n_units_in_pop = len(units_of_interest)\n",
    "                print('n_inh_units_in_layer: ', n_units_in_pop)\n",
    "            else:\n",
    "                units_of_interest = exc_units_layers_all_sessions[sesNr][layPopNr+1]\n",
    "                n_units_in_pop = len(units_of_interest)\n",
    "                print('n_exc_units_in_pop: ', n_units_in_pop)\n",
    "            \n",
    "            if n_units_in_pop == 0:\n",
    "                fir_rate_all_cells_layers[layPopName] = []\n",
    "            else:\n",
    "                temp_spike_counts = session.presentationwise_spike_counts(\n",
    "                bin_edges=time_bin_edges,\n",
    "                stimulus_presentation_ids=flash_250_ms_stimulus_presentation_ids,\n",
    "                unit_ids=units_of_interest\n",
    "                )\n",
    "                \n",
    "                # Transpose because my personal preference is that the unit is the first dimension\n",
    "                # (time is second dimension, trials is third dimension)\n",
    "                print('shape temp_spike_counts.T: ', np.shape(temp_spike_counts.T))\n",
    "                \n",
    "                # Compute average and scale to Hz\n",
    "                temp_trial_avg = np.mean(temp_spike_counts.T, axis = 2)/ratio_bins_second\n",
    "                \n",
    "                fir_rate_all_cells_layers[layPopName] = temp_trial_avg\n",
    "                \n",
    "        fir_rates_all_cells_sessions[list_session_ids_string[sesNr]] = fir_rate_all_cells_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
